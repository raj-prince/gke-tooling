apiVersion: batch/v1
kind: Job
metadata:
  name: with-inactive-stream-timeout-15s-1-27
spec:
  parallelism: 1
  completions: 1
  completionMode: Indexed
  template:
    metadata:
      labels:
        app: ssiog-job
      annotations:
        gke-gcsfuse/volumes: "true"
        gke-gcsfuse/cpu-limit: "0"
        gke-gcsfuse/memory-limit: "0"
        gke-gcsfuse/ephemeral-storage-limit: "0"
    spec:
      restartPolicy: Never
      serviceAccountName: warp-benchmark
      # hostNetwork: true
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchExpressions:
                  - key: app
                    operator: In
                    values:
                      - ssiog-job
              topologyKey: "kubernetes.io/hostname"
      tolerations:
        - key: "checkpoint"
          operator: "Equal"
          value: "yes"
          effect: "NoSchedule"
      containers:
        - name: gke-gcsfuse-sidecar
          image: gcr.io/gcs-tess/princer/gcs-fuse-csi-driver-sidecar-mounter:v1.13.3-latest
        - name: ssiog-benchmark
          image: us-west1-docker.pkg.dev/gcs-tess/ssiog-training/enhanced_debug@sha256:e8ba399e5f19af6129890df391f96f20fc854fbad8c79977ae1458dea7b6d0cc
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: JOB_COMPLETION_INDEX
              valueFrom:
                fieldRef:
                  fieldPath: metadata.annotations['batch.kubernetes.io/job-completion-index']
            - name: JOB_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.labels['job-name']
          securityContext:
            privileged: true
          command:
            - /bin/bash
            - -c
            - |
              mkdir -p /mnt/benchmark-output/metrics/${JOB_NAME} || true
              mkdir -p /mnt/benchmark-output/elapsed_time/${JOB_NAME} || true
              mkdir -p /output/${JOB_NAME} || true
              args=(
                --prefix /mnt/benchmark-input/12G/
                --object-count-limit=200
                --epochs=1
                --background-threads=96
                --sample-size=131072
                --steps=10
                --batch-size=98304
                --group-size=1
                --log-metrics=True
                --metrics-file=/output/${JOB_NAME}/${POD_NAME}.csv
                --log-level=INFO
                --read-order=FullRandom
                --label=test_0-0-0-0
              )
              /app/training.py "${args[@]}"

              echo "Copying the local metrics to bucket..."
              cp /output/${JOB_NAME}/${POD_NAME}.csv /mnt/benchmark-output/metrics/${JOB_NAME}/
          volumeMounts:
            - mountPath: /mnt/benchmark-output
              name: gcsfuse-output
              readOnly: false
            - mountPath: /mnt/benchmark-input
              name: mnt-input
              readOnly: true
      volumes:
        - name: gcsfuse-output
          csi:
            driver: gcsfuse.csi.storage.gke.io
            volumeAttributes:
              skipCSIBucketAccessCheck: "true"
              bucketName: vipinydv-logs-and-metrics
              mountOptions: "log-severity=trace"
        - name: mnt-input
          csi:
            driver: gcsfuse.csi.storage.gke.io
            readOnly: false
            volumeAttributes:
              skipCSIBucketAccessCheck: "true"
              bucketName: princer-ssiog-data-bkt-uc1
              mountOptions: "read-inactive-stream-timeout=15s,logging:severity:trace,implicit-dirs,metadata-cache:stat-cache-max-size-mb:-1,metadata-cache:ttl-secs:-1"
